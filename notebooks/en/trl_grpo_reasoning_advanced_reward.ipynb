{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# GRPO Fine-tuning with TRL Only\n\n_Authored by: [Behrooz Azarkhalili](https://github.com/behroozazarkhalili)_\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/behroozazarkhalili/GRPO-Qwen-Finetuning-Unsloth/blob/master/TRL_GRPO_Reasoning.ipynb)\n\nThis notebook demonstrates **GRPO (Group Relative Policy Optimization)** fine-tuning for mathematical reasoning using TRL (Transformers Reinforcement Learning) library without Unsloth.\n\n## What is GRPO?\n\nGRPO is an advanced reinforcement learning technique for fine-tuning language models that:\n- **Groups similar responses** and compares them relatively instead of using absolute rewards\n- **Optimizes for structured outputs** by rewarding proper format adherence and correct reasoning\n- **Balances exploration vs exploitation** through group-based reward comparison\n- **Handles complex reward functions** like format matching, answer correctness, and reasoning quality\n\n## Key Features of This Implementation:\n\nðŸŽ¯ **Multi-Reward Training**: Uses 4 different reward functions:\n- Format matching (exact/approximate) \n- Answer correctness with fuzzy matching\n- Number extraction validation\n- Structured reasoning rewards\n\nðŸ“Š **Advanced Progress Tracking**: HuggingFace-style interactive table with real-time metrics:\n- Training Loss, Reward, Average Reward, Best Reward\n- Reward Standard Deviation, KL Divergence, Gradient Norm\n- JSON logging for complete training history\n\nðŸ§  **Mathematical Reasoning**: Trains on GSM8K dataset to generate structured responses with:\n- `<start_working_out>` reasoning sections `<end_working_out>`\n- `<SOLUTION>` final answers `</SOLUTION>`\n- Step-by-step mathematical problem solving\n\nâš¡ **Memory Efficient**: Uses 4-bit quantization, LoRA adapters, and optimized batch sizes for training on consumer GPUs.\n\n## Dataset: GSM8K\n\nUsing the **GSM8K** (Grade School Math 8K) dataset - a collection of 8,000+ linguistically diverse grade school math word problems requiring multi-step reasoning. The model learns to:\n1. Parse the problem statement\n2. Generate step-by-step working\n3. Provide final numerical answers\n4. Follow structured output format"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install required packages\n!pip install transformers datasets trl bitsandbytes peft"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Setup\n",
    "\n",
    "Force single GPU training to avoid NCCL errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force single GPU training to avoid NCCL errors\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Use only GPU 1\n",
    "\n",
    "# Verify GPU setup\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport re\nfrom transformers import (\n    AutoModelForCausalLM, \n    AutoTokenizer, \n    BitsAndBytesConfig,\n)\nfrom peft import LoraConfig, get_peft_model, TaskType\nfrom datasets import load_dataset\nfrom trl import GRPOConfig, GRPOTrainer\nimport logging\n\n# Set up logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Model configuration\nmodel_name = \"Qwen/Qwen2.5-3B-Instruct\"  # You can change this to any model you prefer\n# Alternative models:\n# model_name = \"microsoft/DialoGPT-small\"\n# model_name = \"gpt2\"\n# model_name = \"google/gemma-2b\"\n\nmax_seq_length = 2048\n\n# Quantization config for memory efficiency\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=True,\n)\n\n# Load model and tokenizer with correct device mapping\n# Since CUDA_VISIBLE_DEVICES=\"1\" is set, GPU 1 becomes device 0 from PyTorch's perspective\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    device_map={\"\": 0},  # Use device 0 (which is actually GPU 1 due to CUDA_VISIBLE_DEVICES)\n    trust_remote_code=True\n)\n\ntokenizer = AutoTokenizer.from_pretrained(\n    model_name,\n    trust_remote_code=True\n)\n\nprint(f\"Model loaded: {model_name}\")\nprint(f\"Model device: {model.device}\")\nprint(f\"Tokenizer vocab size: {len(tokenizer)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  # Rank\n",
    "    lora_alpha=32,  # Alpha\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Target modules - adjust based on your model\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    ")\n",
    "\n",
    "# Apply LoRA to the model\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reasoning format tokens\n",
    "reasoning_start = \"<start_working_out>\"\n",
    "reasoning_end = \"<end_working_out>\"\n",
    "solution_start = \"<SOLUTION>\"\n",
    "solution_end = \"</SOLUTION>\"\n",
    "\n",
    "# System prompt for reasoning\n",
    "system_prompt = f\"\"\"You are given a problem.\n",
    "Think about the problem and provide your working out.\n",
    "Place it between {reasoning_start} and {reasoning_end}.\n",
    "Then, provide your solution between {solution_start}{solution_end}\"\"\"\n",
    "\n",
    "def extract_hash_answer(text):\n",
    "    \"\"\"Extract answer after #### in GSM8K format\"\"\"\n",
    "    if \"####\" not in text:\n",
    "        return None\n",
    "    return text.split(\"####\")[1].strip()\n",
    "\n",
    "def process_dataset_example(example):\n",
    "    \"\"\"Process a single GSM8K example\"\"\"\n",
    "    question = example[\"question\"]\n",
    "    answer = extract_hash_answer(example[\"answer\"])\n",
    "    \n",
    "    prompt = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"answer\": answer,\n",
    "    }\n",
    "\n",
    "# Load and process GSM8K dataset\n",
    "print(\"Loading GSM8K dataset...\")\n",
    "dataset = load_dataset(\"openai/gsm8k\", \"main\", split=\"train\")\n",
    "dataset = dataset.map(process_dataset_example)\n",
    "\n",
    "print(f\"Dataset loaded with {len(dataset)} examples\")\n",
    "print(\"Sample example:\")\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex patterns for reward functions\n",
    "match_format = re.compile(\n",
    "    rf\"^[\\s]{{0,}}\"\n",
    "    rf\"{reasoning_start}.+?{reasoning_end}.*?\"\n",
    "    rf\"{solution_start}(.+?){solution_end}\"\n",
    "    rf\"[\\s]{{0,}}$\",\n",
    "    flags=re.MULTILINE | re.DOTALL\n",
    ")\n",
    "\n",
    "match_numbers = re.compile(\n",
    "    rf\"{solution_start}.*?([\\d\\.]{{1,}})\",\n",
    "    flags=re.MULTILINE | re.DOTALL\n",
    ")\n",
    "\n",
    "def match_format_exactly(completions, **kwargs):\n",
    "    \"\"\"Reward for exact format matching\"\"\"\n",
    "    scores = []\n",
    "    for completion in completions:\n",
    "        response = completion[0][\"content\"]\n",
    "        score = 3.0 if match_format.search(response) is not None else 0.0\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "def match_format_approximately(completions, **kwargs):\n",
    "    \"\"\"Reward for approximate format matching\"\"\"\n",
    "    scores = []\n",
    "    for completion in completions:\n",
    "        response = completion[0][\"content\"]\n",
    "        score = 0\n",
    "        \n",
    "        # Count occurrences of format tokens\n",
    "        score += 0.5 if response.count(reasoning_start) == 1 else -0.5\n",
    "        score += 0.5 if response.count(reasoning_end) == 1 else -0.5\n",
    "        score += 0.5 if response.count(solution_start) == 1 else -0.5\n",
    "        score += 0.5 if response.count(solution_end) == 1 else -0.5\n",
    "        \n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "def check_answer_correctness(prompts, completions, answer, **kwargs):\n",
    "    \"\"\"Reward for correct answers\"\"\"\n",
    "    question = prompts[0][-1][\"content\"]\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    \n",
    "    extracted_responses = [\n",
    "        guess.group(1) if (guess := match_format.search(r)) is not None else None\n",
    "        for r in responses\n",
    "    ]\n",
    "    \n",
    "    scores = []\n",
    "    for guess, true_answer in zip(extracted_responses, answer):\n",
    "        if guess is None:\n",
    "            scores.append(0)\n",
    "            continue\n",
    "            \n",
    "        # Exact match gets full points\n",
    "        if guess == true_answer:\n",
    "            scores.append(3.0)\n",
    "        # Strip whitespace and try again\n",
    "        elif guess.strip() == true_answer.strip():\n",
    "            scores.append(1.5)\n",
    "        else:\n",
    "            # Try numerical comparison\n",
    "            try:\n",
    "                ratio = float(guess) / float(true_answer)\n",
    "                if 0.9 <= ratio <= 1.1:\n",
    "                    scores.append(0.5)\n",
    "                elif 0.8 <= ratio <= 1.2:\n",
    "                    scores.append(0.25)\n",
    "                else:\n",
    "                    scores.append(-1.0)\n",
    "            except:\n",
    "                scores.append(-0.5)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def check_numbers_extraction(prompts, completions, answer, **kwargs):\n",
    "    \"\"\"Reward for extracting numbers from solution\"\"\"\n",
    "    question = prompts[0][-1][\"content\"]\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    \n",
    "    extracted_responses = [\n",
    "        guess.group(1) if (guess := match_numbers.search(r)) is not None else None\n",
    "        for r in responses\n",
    "    ]\n",
    "    \n",
    "    scores = []\n",
    "    print('*' * 20, f\"Question:\\n{question}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\")\n",
    "    \n",
    "    for guess, true_answer in zip(extracted_responses, answer):\n",
    "        if guess is None:\n",
    "            scores.append(0)\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            true_answer = float(true_answer.strip())\n",
    "            guess = float(guess.strip())\n",
    "            scores.append(1.5 if guess == true_answer else 0.0)\n",
    "        except:\n",
    "            scores.append(0)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "print(\"Reward functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# GRPO Training configuration with enhanced logging\ntraining_args = GRPOConfig(\n    learning_rate=5e-6,\n    adam_beta1=0.9,\n    adam_beta2=0.99,\n    weight_decay=0.1,\n    warmup_ratio=0.1,\n    lr_scheduler_type=\"cosine\",\n    optim=\"adamw_torch_fused\",\n    logging_steps=1,  # Log every step\n    per_device_train_batch_size=2,  # Start small to avoid memory issues\n    gradient_accumulation_steps=8,  # Increase to maintain effective batch size\n    max_prompt_length=1024,  # Reduce if needed\n    max_completion_length=1024,  # Reduce if needed\n    max_steps=10,  # Reduce for testing\n    save_steps=10,\n    eval_steps=1,  # Enable evaluation logging\n    max_grad_norm=0.1,\n    report_to=\"none\",  # Disable reporting to external services\n    output_dir=\"./trl_grpo_outputs\",\n    logging_dir=\"./logs\",  # Directory for logs\n    dataloader_drop_last=True,\n    # Enhanced logging options\n    log_level=\"info\",\n    logging_first_step=True,\n    logging_nan_inf_filter=True,\n    metric_for_best_model=\"reward\",\n    greater_is_better=True,\n    # Keep default progress bar enabled\n    disable_tqdm=False,\n)\n\nprint(\"Training configuration with enhanced default progress bar:\")\nprint(f\"Batch size: {training_args.per_device_train_batch_size}\")\nprint(f\"Gradient accumulation: {training_args.gradient_accumulation_steps}\")\nprint(f\"Effective batch size: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\nprint(f\"Max steps: {training_args.max_steps}\")\nprint(f\"Learning rate: {training_args.learning_rate}\")\nprint(f\"Logging every: {training_args.logging_steps} steps\")\nprint(f\"Evaluation every: {training_args.eval_steps} steps\")\nprint(f\"Default tqdm enabled: {not training_args.disable_tqdm}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.trainer_callback import TrainerCallback\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict, deque\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import io\n",
    "import sys\n",
    "\n",
    "class HuggingFaceStyleTableCallback(TrainerCallback):\n",
    "    \"\"\"Callback that displays a HuggingFace-style interactive table that updates in-place below progress bar\"\"\"\n",
    "    \n",
    "    def __init__(self, log_file=\"training_logs.json\"):\n",
    "        self.recent_rewards = deque(maxlen=5)\n",
    "        self.best_reward = float('-inf')\n",
    "        self.log_file = log_file\n",
    "        self.all_logs = []\n",
    "        self.metrics_data = []\n",
    "        self.table_displayed = False\n",
    "        \n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        \"\"\"Initialize logging\"\"\"\n",
    "        self.all_logs = []\n",
    "        self.metrics_data = []\n",
    "        self.table_displayed = False\n",
    "        print(f\"Training started - HuggingFace-style interactive table will appear below progress bar\")\n",
    "        print(f\"All logs saved to: {self.log_file}\")\n",
    "        \n",
    "    def _display_hf_style_table(self):\n",
    "        \"\"\"Display HuggingFace-style table that updates in-place\"\"\"\n",
    "        if not self.metrics_data:\n",
    "            return\n",
    "            \n",
    "        # Create DataFrame from metrics data\n",
    "        df = pd.DataFrame(self.metrics_data)\n",
    "        \n",
    "        # Style similar to HuggingFace trainer tables\n",
    "        styled_html = f\"\"\"\n",
    "        <div style=\"margin: 10px 0;\">\n",
    "        <table style=\"border-collapse: collapse; margin: auto; width: 100%; max-width: 1000px;\">\n",
    "        <thead>\n",
    "        <tr style=\"border-bottom: 2px solid #dee2e6;\">\n",
    "        <th style=\"padding: 12px; text-align: center; border: 1px solid #dee2e6; font-weight: bold;\">Step</th>\n",
    "        <th style=\"padding: 12px; text-align: center; border: 1px solid #dee2e6; font-weight: bold;\">Training-Loss</th>\n",
    "        <th style=\"padding: 12px; text-align: center; border: 1px solid #dee2e6; font-weight: bold;\">Reward</th>\n",
    "        <th style=\"padding: 12px; text-align: center; border: 1px solid #dee2e6; font-weight: bold;\">Reward-Avg</th>\n",
    "        <th style=\"padding: 12px; text-align: center; border: 1px solid #dee2e6; font-weight: bold;\">Reward-Std</th>\n",
    "        <th style=\"padding: 12px; text-align: center; border: 1px solid #dee2e6; font-weight: bold;\">Reward-Best</th>\n",
    "        <th style=\"padding: 12px; text-align: center; border: 1px solid #dee2e6; font-weight: bold;\">Grad-Norm</th>\n",
    "        <th style=\"padding: 12px; text-align: center; border: 1px solid #dee2e6; font-weight: bold;\">KL-Div</th>\n",
    "        </tr>\n",
    "        </thead>\n",
    "        <tbody>\n",
    "        \"\"\"\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            styled_html += f\"\"\"\n",
    "            <tr style=\"{''}\">\n",
    "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">{int(row['Step'])}</td>\n",
    "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">{row['Training-Loss']:.6f}</td>\n",
    "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">{row['Reward']:.6f}</td>\n",
    "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">{row['Reward-Avg']:.6f}</td>\n",
    "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">{row['Reward-Std']:.6f}</td>\n",
    "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">{row['Reward-Best']:.6f}</td>\n",
    "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">{row['Grad-Norm']:.6f}</td>\n",
    "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">{row['KL-Div']:.6f}</td>\n",
    "            </tr>\n",
    "            \"\"\"\n",
    "        \n",
    "        styled_html += \"\"\"\n",
    "        </tbody>\n",
    "        </table>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Use clear_output to update in-place like HuggingFace trainers do\n",
    "        if self.table_displayed:\n",
    "            clear_output(wait=True)\n",
    "        \n",
    "        print(\"TRAINING METRICS:\")\n",
    "        display(HTML(styled_html))\n",
    "        self.table_displayed = True\n",
    "        \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        \"\"\"Log metrics and update interactive table in-place\"\"\"\n",
    "        if logs is None:\n",
    "            return\n",
    "            \n",
    "        current_step = state.global_step\n",
    "        \n",
    "        # Save complete logs to JSON file with Unix timestamp\n",
    "        log_entry = {\n",
    "            \"step\": current_step,\n",
    "            \"timestamp\": time.time(),\n",
    "            **logs\n",
    "        }\n",
    "        self.all_logs.append(log_entry)\n",
    "        \n",
    "        # Write to JSON file after each step\n",
    "        try:\n",
    "            with open(self.log_file, 'w') as f:\n",
    "                json.dump(self.all_logs, f, indent=2)\n",
    "        except Exception as e:\n",
    "            pass  # Silent fail\n",
    "        \n",
    "        # Extract metrics from logs\n",
    "        reward = logs.get('reward', 0.0)\n",
    "        reward_std = logs.get('reward_std', 0.0)\n",
    "        loss = logs.get('loss', 0.0)\n",
    "        kl_div = logs.get('kl', 0.0)\n",
    "        grad_norm = logs.get('grad_norm', 0.0)\n",
    "        \n",
    "        # Track enhanced metrics\n",
    "        if reward != 0:\n",
    "            self.recent_rewards.append(reward)\n",
    "            if reward > self.best_reward:\n",
    "                self.best_reward = reward\n",
    "                \n",
    "        reward_avg = sum(self.recent_rewards) / len(self.recent_rewards) if self.recent_rewards else 0.0\n",
    "        \n",
    "        # Add new row to metrics data\n",
    "        new_row = {\n",
    "            'Step': current_step,\n",
    "            'Training-Loss': loss,\n",
    "            'Reward': reward,\n",
    "            'Reward-Avg': reward_avg,\n",
    "            'Reward-Std': reward_std,\n",
    "            'Reward-Best': self.best_reward,\n",
    "            'Grad-Norm': grad_norm,\n",
    "            'KL-Div': kl_div,\n",
    "        }\n",
    "        self.metrics_data.append(new_row)\n",
    "        \n",
    "        # Update the table in-place\n",
    "        self._display_hf_style_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize GRPO trainer with HuggingFace-style interactive table callback\nhf_table_callback = HuggingFaceStyleTableCallback()\n\ntrainer = GRPOTrainer(\n    model=model,\n    reward_funcs=[\n        match_format_exactly,\n        match_format_approximately,\n        check_answer_correctness,\n        check_numbers_extraction,\n    ],\n    args=training_args,\n    train_dataset=dataset,\n    callbacks=[hf_table_callback],  # Add HuggingFace-style table callback\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize GRPO trainer without HuggingFace-style table callback\n",
    "# Uncomment the following lines if you want to use the original GRPOTrainer without the interactive table\n",
    "\n",
    "# trainer = GRPOTrainer(\n",
    "#     model=model,\n",
    "#     processing_class=tokenizer,\n",
    "#     reward_funcs=[\n",
    "#         match_format_exactly,\n",
    "#         match_format_approximately,\n",
    "#         check_answer_correctness,\n",
    "#         check_numbers_extraction,\n",
    "#     ],\n",
    "#     args=training_args,\n",
    "#     train_dataset=dataset,\n",
    "# )\n",
    "\n",
    "# print(\"Trainer initialized!\")\n",
    "# print(f\"Model device: {model.device}\")\n",
    "# print(f\"Number of training examples: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Start Training",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING METRICS:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin: 10px 0;\">\n",
       "        <table style=\"border-collapse: collapse; margin: auto; width: 100%; max-width: 1000px;\">\n",
       "        <thead>\n",
       "        <tr style=\"border-bottom: 2px solid #dee2e6;\">\n",
       "        <th style=\"padding: 12px; text-align: center; border: 1px solid #dee2e6; font-weight: bold;\">Step</th>\n",
       "        <th style=\"padding: 12px; text-align: center; border: 1px solid #dee2e6; font-weight: bold;\">TrainingLoss</th>\n",
       "        <th style=\"padding: 12px; text-align: center; border: 1px solid #dee2e6; font-weight: bold;\">Reward</th>\n",
       "        <th style=\"padding: 12px; text-align: center; border: 1px solid #dee2e6; font-weight: bold;\">Reward-Avg</th>\n",
       "        <th style=\"padding: 12px; text-align: center; border: 1px solid #dee2e6; font-weight: bold;\">Reward-Std</th>\n",
       "        <th style=\"padding: 12px; text-align: center; border: 1px solid #dee2e6; font-weight: bold;\">Reward-Best</th>\n",
       "        <th style=\"padding: 12px; text-align: center; border: 1px solid #dee2e6; font-weight: bold;\">Grad-Norm</th>\n",
       "        <th style=\"padding: 12px; text-align: center; border: 1px solid #dee2e6; font-weight: bold;\">KL-Div</th>\n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"\">\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">1</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.020200</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.625000</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.625000</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">2.528742</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.625000</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.096231</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.000000</td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr style=\"\">\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">2</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.030600</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.906250</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.765625</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">2.631696</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.906250</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.206910</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.000000</td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr style=\"\">\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.037200</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.687500</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.739583</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">2.016598</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.906250</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.205314</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.000000</td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr style=\"\">\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">4</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.085700</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.125000</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.585938</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">1.735451</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.906250</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.146251</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.000000</td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr style=\"\">\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">5</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">-0.055200</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.625000</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.593750</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.818543</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.906250</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.169046</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.000000</td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr style=\"\">\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">6</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">-0.072800</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.468750</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.562500</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">1.627355</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.906250</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.214777</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.000000</td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr style=\"\">\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">7</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">-0.022700</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">2.437500</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.268750</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">2.135396</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.906250</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.203865</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.000000</td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr style=\"\">\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">8</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">-0.115800</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.406250</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.212500</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">2.789666</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.906250</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.155323</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.000000</td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr style=\"\">\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">9</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.027200</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">2.625000</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.112500</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">1.949140</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.906250</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.227745</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.000000</td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr style=\"\">\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">10</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">-0.054000</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.437500</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.075000</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">2.856393</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.906250</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.172547</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.000000</td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr style=\"\">\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">10</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.000000</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.000000</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.075000</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.000000</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">3.906250</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.000000</td>\n",
       "            <td style=\"padding: 8px; text-align: center; border: 1px solid #dee2e6;\">0.000000</td>\n",
       "            </tr>\n",
       "            \n",
       "        </tbody>\n",
       "        </table>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "print(\"Starting GRPO training...\")\n",
    "print(\"This may take a while. Monitor the reward column for improvements.\")\n",
    "print(\"Initial rewards might be low/negative - this is normal.\")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is 25 + 17?\n",
      "\n",
      "Model Response:\n",
      "we can add the numbers step by step.\n",
      "\n",
      "First, let's add the units digits (5 + 7):\n",
      "\\[ 5 + 7 = 12 \\]\n",
      "\n",
      "Next, we carry over the tens digit from this sum to the tens place. So we write down 2 and carry over 1.\n",
      "\n",
      "Now, let's add the tens digits along with the carried over 1:\n",
      "\\[ 2 + 1 + 1 = 4 \\]\n",
      "\n",
      "Putting it all together, we get:\n",
      "\\[ 25 + 17 = 42 \\]\n",
      "<end_working_out>\n",
      "<SOLUTION>\n",
      "42\n",
      "</SOLUTION>\n"
     ]
    }
   ],
   "source": [
    "# Test the trained model\n",
    "def test_model(question):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "    ]\n",
    "    \n",
    "    # Format the prompt\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        tokenize=False,\n",
    "    )\n",
    "    \n",
    "    # Generate response\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=512,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Extract only the generated part\n",
    "    response = response[len(text):].strip()\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Test with a sample question\n",
    "test_question = \"What is 25 + 17?\"\n",
    "print(f\"Question: {test_question}\")\n",
    "print(\"\\nModel Response:\")\n",
    "print(test_model(test_question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with GSM8K Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSM8K Question: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
      "\n",
      "Model Response:\n",
      "old altogether in April and May, we need to follow these steps:\n",
      "\n",
      "1. Determine the number of clips sold in May, which is half the number sold in April.\n",
      "2. Calculate the total number of clips sold in both months by adding the number sold in April to the number sold in May.\n",
      "\n",
      "Given:\n",
      "- Natalia sold 48 clips in April.\n",
      "- She sold half as many clips in May.\n",
      "\n",
      "First, let's calculate the number of clips sold in May:\n",
      "<end_working_out]\n",
      "<May_sales> = 48 / 2\n",
      "<end_working_out]\n",
      "<total_sales> = April_sales + May_sales\n",
      "<total_sales> = 48 + (<May_sales>)\n",
      "<end_working_out]\n",
      "<SOLUTION>\n",
      "Total clips sold by Natalia in April and May is 60.\n",
      "<END_OF_SOLUTION>\n",
      "\n",
      "Expected Answer: 72\n"
     ]
    }
   ],
   "source": [
    "# Test with a GSM8K example\n",
    "gsm8k_question = \"Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\"\n",
    "print(f\"GSM8K Question: {gsm8k_question}\")\n",
    "print(\"\\nModel Response:\")\n",
    "print(test_model(gsm8k_question))\n",
    "print(\"\\nExpected Answer: 72\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory cleared\n"
     ]
    }
   ],
   "source": [
    "# Clear GPU memory if needed\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "print(\"GPU memory cleared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "### Papers and Research\n",
    "- **GRPO Algorithm**: [Group Relative Policy Optimization](https://arxiv.org/abs/2402.03300) - The original GRPO paper introducing group-based relative policy optimization\n",
    "- **GSM8K Dataset**: [Training Verifiers to Solve Math Word Problems](https://arxiv.org/abs/2110.14168) - Cobbe et al., OpenAI\n",
    "- **LoRA**: [Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685) - Hu et al., Microsoft\n",
    "- **QLoRA**: [Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314) - Dettmers et al., 4-bit quantization for efficient training\n",
    "\n",
    "### Libraries and Frameworks\n",
    "- **TRL (Transformers Reinforcement Learning)**: [HuggingFace TRL](https://github.com/huggingface/trl) - Official library for RLHF and advanced training techniques\n",
    "- **Transformers**: [HuggingFace Transformers](https://github.com/huggingface/transformers) - State-of-the-art NLP library\n",
    "- **PEFT**: [Parameter-Efficient Fine-Tuning](https://github.com/huggingface/peft) - Efficient adaptation methods\n",
    "- **BitsAndBytes**: [8-bit & 4-bit Quantization](https://github.com/TimDettmers/bitsandbytes) - Memory-efficient training\n",
    "\n",
    "### Models Used\n",
    "- **Qwen2.5-3B-Instruct**: [Qwen Model Series](https://github.com/QwenLM/Qwen2.5) - Alibaba's instruction-tuned language model\n",
    "- **Alternative Models**: Gemma-2B, DialoGPT, GPT-2 (configurable in the notebook)\n",
    "\n",
    "### Datasets\n",
    "- **GSM8K**: [OpenAI GSM8K](https://huggingface.co/datasets/openai/gsm8k) - Grade School Math 8K problems dataset\n",
    "- **Format**: Mathematical word problems requiring multi-step reasoning and numerical answers\n",
    "\n",
    "### Key Concepts\n",
    "- **Reinforcement Learning from Human Feedback (RLHF)**: Training language models using reward signals\n",
    "- **Group Relative Policy Optimization**: Advanced RL technique comparing responses in groups rather than absolute scoring\n",
    "- **Structured Generation**: Teaching models to follow specific output formats with reasoning sections\n",
    "- **Multi-Reward Training**: Using multiple reward functions for comprehensive evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "behrooz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}