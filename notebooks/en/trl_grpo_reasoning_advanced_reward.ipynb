{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced GRPO Fine-tuning for Mathematical Reasoning with Multi-Reward Training\n",
    "\n",
    "_Authored by: [Behrooz Azarkhalili](https://github.com/behroozazarkhalili)_\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/behroozazarkhalili/GRPO-Qwen-Finetuning-Unsloth/blob/master/TRL_GRPO_Reasoning.ipynb)\n",
    "\n",
    "This notebook demonstrates **advanced GRPO (Group Relative Policy Optimization)** for mathematical reasoning using a comprehensive multi-reward training system. We'll fine-tune a model on the GSM8K dataset with four specialized reward functions.\n",
    "\n",
    "**Key Features:**\n",
    "- **4 Reward Functions**: Format compliance, approximate matching, answer correctness, and number extraction\n",
    "- **Memory Efficient**: 4-bit quantization + LoRA for consumer GPUs\n",
    "- **Interactive Monitoring**: Real-time training metrics with trackio dashboard\n",
    "- **Structured Output**: Enforces step-by-step reasoning format\n",
    "\n",
    "The model learns to generate structured mathematical solutions with clear reasoning steps and accurate numerical answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and Setup\n",
    "\n",
    "Install the required packages for GRPO training with memory-efficient techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (4.53.2)\n",
      "Requirement already satisfied: datasets in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (4.0.0)\n",
      "Requirement already satisfied: trl in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (0.20.0)\n",
      "Requirement already satisfied: bitsandbytes in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (0.46.1)\n",
      "Requirement already satisfied: peft in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (0.15.2)\n",
      "Requirement already satisfied: trackio in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (0.2.2)\n",
      "Requirement already satisfied: filelock in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from transformers) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from datasets) (2.3.1)\n",
      "Requirement already satisfied: xxhash in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.14)\n",
      "Requirement already satisfied: accelerate>=1.4.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from trl) (1.8.1)\n",
      "Requirement already satisfied: torch<3,>=2.2 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from bitsandbytes) (2.7.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from torch<3,>=2.2->bitsandbytes) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from torch<3,>=2.2->bitsandbytes) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from torch<3,>=2.2->bitsandbytes) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from torch<3,>=2.2->bitsandbytes) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from torch<3,>=2.2->bitsandbytes) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from torch<3,>=2.2->bitsandbytes) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from torch<3,>=2.2->bitsandbytes) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from torch<3,>=2.2->bitsandbytes) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from torch<3,>=2.2->bitsandbytes) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from torch<3,>=2.2->bitsandbytes) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from torch<3,>=2.2->bitsandbytes) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from torch<3,>=2.2->bitsandbytes) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from torch<3,>=2.2->bitsandbytes) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from triton==3.3.1->torch<3,>=2.2->bitsandbytes) (80.9.0)\n",
      "Requirement already satisfied: psutil in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: gradio>=5.35.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from trackio) (5.39.0)\n",
      "Requirement already satisfied: tbparse in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from trackio) (0.0.9)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from gradio>=5.35.0->trackio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from gradio>=5.35.0->trackio) (4.9.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from gradio>=5.35.0->trackio) (1.1.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from gradio>=5.35.0->trackio) (0.115.12)\n",
      "Requirement already satisfied: ffmpy in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from gradio>=5.35.0->trackio) (0.6.1)\n",
      "Requirement already satisfied: gradio-client==1.11.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from gradio>=5.35.0->trackio) (1.11.0)\n",
      "Requirement already satisfied: groovy~=0.1 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from gradio>=5.35.0->trackio) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from gradio>=5.35.0->trackio) (0.28.1)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from gradio>=5.35.0->trackio) (3.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from gradio>=5.35.0->trackio) (3.10.18)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from gradio>=5.35.0->trackio) (11.3.0)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from gradio>=5.35.0->trackio) (2.11.5)\n",
      "Requirement already satisfied: pydub in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from gradio>=5.35.0->trackio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from gradio>=5.35.0->trackio) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from gradio>=5.35.0->trackio) (0.12.7)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from gradio>=5.35.0->trackio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from gradio>=5.35.0->trackio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from gradio>=5.35.0->trackio) (0.46.2)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from gradio>=5.35.0->trackio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from gradio>=5.35.0->trackio) (0.16.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from gradio>=5.35.0->trackio) (0.34.3)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from gradio-client==1.11.0->gradio>=5.35.0->trackio) (15.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio>=5.35.0->trackio) (1.3.1)\n",
      "Requirement already satisfied: certifi in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from httpx<1.0,>=0.24.1->gradio>=5.35.0->trackio) (2025.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from httpx<1.0,>=0.24.1->gradio>=5.35.0->trackio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio>=5.35.0->trackio) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from pydantic<2.12,>=2.0->gradio>=5.35.0->trackio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from pydantic<2.12,>=2.0->gradio>=5.35.0->trackio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from pydantic<2.12,>=2.0->gradio>=5.35.0->trackio) (0.4.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio>=5.35.0->trackio) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio>=5.35.0->trackio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio>=5.35.0->trackio) (14.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=5.35.0->trackio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=5.35.0->trackio) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=5.35.0->trackio) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from sympy>=1.13.3->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: tensorboard>=2.12.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from tbparse->trackio) (2.19.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from tensorboard>=2.12.0->tbparse->trackio) (2.3.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from tensorboard>=2.12.0->tbparse->trackio) (1.74.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from tensorboard>=2.12.0->tbparse->trackio) (3.8)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from tensorboard>=2.12.0->tbparse->trackio) (6.32.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from tensorboard>=2.12.0->tbparse->trackio) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages (from tensorboard>=2.12.0->tbparse->trackio) (3.1.3)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages for GRPO mathematical reasoning training\n",
    "!pip install transformers datasets trl bitsandbytes peft trackio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Environment Detection\n",
    "\n",
    "Verify GPU availability and display hardware specifications for optimal training configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs: 2\n",
      "Current GPU: 0\n",
      "GPU name: NVIDIA H100 NVL\n",
      "GPU memory: 100.0 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Verify CUDA availability and display GPU specifications\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Display current GPU details for training optimization\n",
    "    print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    # Provide guidance for enabling GPU in Colab\n",
    "    print(\"⚠️  No GPU available. This notebook requires a GPU for efficient training.\")\n",
    "    print(\"In Colab: Runtime → Change runtime type → Hardware accelerator → GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Library Imports\n",
    "\n",
    "Import essential libraries for GRPO training, model configuration, and experiment tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-23 14:46:50 [__init__.py:244] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import trackio  # Experiment tracking dashboard\n",
    "import re       # Regex patterns for reward functions\n",
    "\n",
    "# GRPO training components\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "\n",
    "# Model and tokenization\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,   # Causal language model loading\n",
    "    AutoTokenizer,          # Text tokenization\n",
    "    BitsAndBytesConfig,     # Quantization configuration\n",
    ")\n",
    "\n",
    "# Parameter-efficient fine-tuning\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Dataset handling\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Logging configuration\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Suppress httpx request logs that appear during trackio usage\n",
    "# logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "# logging.getLogger(\"gradio_client\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Configuration\n",
    "\n",
    "Choose a compact but capable model suitable for mathematical reasoning with memory constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: Qwen/Qwen2.5-3B-Instruct\n",
      "Max sequence length: 2048\n"
     ]
    }
   ],
   "source": [
    "# Select model optimized for instruction-following and reasoning\n",
    "model_name = \"Qwen/Qwen2.5-3B-Instruct\"  # 3B parameter model balances capability and memory usage\n",
    "max_seq_length = 2048                     # Token limit for mathematical problems (reduce if OOM)\n",
    "\n",
    "print(f\"Loading model: {model_name}\")\n",
    "print(f\"Max sequence length: {max_seq_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 4-bit quantization configured\n",
      "   Memory reduction: ~75% vs FP16\n"
     ]
    }
   ],
   "source": [
    "# Configure 4-bit quantization for ~75% memory reduction\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,                    # Enable 4-bit precision (vs 16-bit default)\n",
    "    bnb_4bit_quant_type=\"nf4\",           # NormalFloat4: optimal for neural network weights\n",
    "    bnb_4bit_compute_dtype=torch.float16, # Use FP16 for forward/backward passes\n",
    "    bnb_4bit_use_double_quant=True,      # Further quantize quantization constants\n",
    ")\n",
    "\n",
    "print(\"✅ 4-bit quantization configured\")\n",
    "print(\"   Memory reduction: ~75% vs FP16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be7413b24ae441c99dbc65b5ea70d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded successfully!\n",
      "📊 Model parameters: ~1698.7M\n",
      "🧮 Quantized parameters: ~1387.3M\n"
     ]
    }
   ],
   "source": [
    "# Load model with quantization and automatic device mapping\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,      # Apply 4-bit quantization\n",
    "    device_map=\"auto\",                   # Auto-distribute across available GPUs/CPU\n",
    "    trust_remote_code=True,              # Allow custom model code execution\n",
    "    torch_dtype=torch.float16,           # Use FP16 for non-quantized operations\n",
    ")\n",
    "\n",
    "# Load corresponding tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True               # Allow custom tokenizer code\n",
    ")\n",
    "\n",
    "# Ensure tokenizer has proper padding token for batch processing\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(f\"✅ Model loaded successfully!\")\n",
    "print(f\"📊 Model parameters: ~{sum(p.numel() for p in model.parameters()) / 1e6:.1f}M\")\n",
    "print(f\"🧮 Quantized parameters: ~{sum(p.numel() for p in model.parameters() if hasattr(p, 'quant_type')) / 1e6:.1f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoRA Configuration\n",
    "\n",
    "Apply Low-Rank Adaptation to train only ~0.1% of parameters while maintaining performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Applying LoRA adaptation to model...\n",
      "📊 LoRA Training Parameters Summary:\n",
      "trainable params: 3,686,400 || all params: 3,089,625,088 || trainable%: 0.1193\n"
     ]
    }
   ],
   "source": [
    "# Configure LoRA for mathematical reasoning adaptation\n",
    "lora_config = LoraConfig(\n",
    "    r=16,                              # Rank: adaptation capacity (16 good for reasoning tasks)\n",
    "    lora_alpha=32,                     # Scaling factor (typically 2x rank)\n",
    "    target_modules=[\"q_proj\", \"v_proj\"], # Focus on attention query/value for reasoning\n",
    "    lora_dropout=0.1,                  # Regularization to prevent overfitting\n",
    "    bias=\"none\",                       # Skip bias adaptation for simplicity\n",
    "    task_type=TaskType.CAUSAL_LM,      # Causal language modeling task\n",
    ")\n",
    "\n",
    "print(\"🔧 Applying LoRA adaptation to model...\")\n",
    "\n",
    "# Apply LoRA configuration to create trainable adapter\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Display parameter efficiency\n",
    "print(\"📊 LoRA Training Parameters Summary:\")\n",
    "model.print_trainable_parameters()  # Shows trainable vs total parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GSM8K Dataset Setup\n",
    "\n",
    "Configure the GSM8K mathematical reasoning dataset with structured output format for step-by-step solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Format tokens and system prompt defined\n",
      "   Reasoning format: <start_working_out> ... <end_working_out>\n",
      "   Solution format: <SOLUTION> ... </SOLUTION>\n"
     ]
    }
   ],
   "source": [
    "# Define structured output format for mathematical reasoning\n",
    "reasoning_start = \"<start_working_out>\"   # Begin reasoning section\n",
    "reasoning_end = \"<end_working_out>\"       # End reasoning section\n",
    "solution_start = \"<SOLUTION>\"            # Begin final answer\n",
    "solution_end = \"</SOLUTION>\"              # End final answer\n",
    "\n",
    "# System prompt that teaches the model our desired reasoning structure\n",
    "system_prompt = f\"\"\"You are a mathematical reasoning assistant.\n",
    "When given a math problem:\n",
    "1. Show your step-by-step work between {reasoning_start} and {reasoning_end}\n",
    "2. Provide your final numerical answer between {solution_start} and {solution_end}\n",
    "3. Be precise and show all calculation steps clearly.\"\"\"\n",
    "\n",
    "print(\"✅ Format tokens and system prompt defined\")\n",
    "print(f\"   Reasoning format: {reasoning_start} ... {reasoning_end}\")\n",
    "print(f\"   Solution format: {solution_start} ... {solution_end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset processing functions defined\n"
     ]
    }
   ],
   "source": [
    "# Dataset processing utilities\n",
    "def extract_hash_answer(text):\n",
    "    \"\"\"Extract numerical answer from GSM8K format (#### marker)\"\"\"\n",
    "    if \"####\" not in text:\n",
    "        return None\n",
    "    # GSM8K uses format: \"Explanation... #### 42\"\n",
    "    return text.split(\"####\")[1].strip()\n",
    "\n",
    "def process_dataset_example(example):\n",
    "    \"\"\"Convert GSM8K example to conversation format for GRPO training\"\"\"\n",
    "    question = example[\"question\"]\n",
    "    answer = extract_hash_answer(example[\"answer\"])\n",
    "    \n",
    "    # Create conversation with system prompt for structured reasoning\n",
    "    prompt = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"prompt\": prompt,           # Input conversation\n",
    "        \"answer\": answer,          # Ground truth for reward functions\n",
    "    }\n",
    "\n",
    "print(\"✅ Dataset processing functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Loading GSM8K mathematical reasoning dataset...\n",
      "✅ Dataset loaded and processed!\n",
      "📊 Training examples: 7,473\n",
      "🎯 Sample question: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?...\n",
      "🎯 Sample answer: 72\n",
      "\n",
      "📋 Example structure:\n",
      "   Prompt: 2 messages (system + user)\n",
      "   Answer: 72 (ground truth for rewards)\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess GSM8K training dataset\n",
    "print(\"🔄 Loading GSM8K mathematical reasoning dataset...\")\n",
    "dataset = load_dataset(\"openai/gsm8k\", \"main\", split=\"train\")\n",
    "\n",
    "# Apply conversation formatting to all examples\n",
    "dataset = dataset.map(process_dataset_example)\n",
    "\n",
    "print(f\"✅ Dataset loaded and processed!\")\n",
    "print(f\"📊 Training examples: {len(dataset):,}\")\n",
    "print(f\"🎯 Sample question: {dataset[0]['prompt'][1]['content']}...\")\n",
    "print(f\"🎯 Sample answer: {dataset[0]['answer']}\")\n",
    "\n",
    "# Show structure of first example for verification\n",
    "print(f\"\\n📋 Example structure:\")\n",
    "print(f\"   Prompt: {len(dataset[0]['prompt'])} messages (system + user)\")\n",
    "print(f\"   Answer: {dataset[0]['answer']} (ground truth for rewards)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Reward System Design\n",
    "\n",
    "Implement four complementary reward functions to evaluate different aspects of mathematical reasoning:\n",
    "1. **Exact Format Matching**: Perfect structure compliance  \n",
    "2. **Approximate Matching**: Partial credit for format elements\n",
    "3. **Answer Correctness**: Mathematical accuracy with graduated scoring\n",
    "4. **Number Extraction**: Ability to parse and output numerical results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiled regex patterns for efficient reward computation\n",
    "match_format = re.compile(\n",
    "    rf\"^[\\s]{{0,}}\"                      # Optional whitespace at start\n",
    "    rf\"{reasoning_start}.+?{reasoning_end}.*?\"  # Reasoning section (non-greedy)\n",
    "    rf\"{solution_start}(.+?){solution_end}\"     # Solution section with capture group\n",
    "    rf\"[\\s]{{0,}}$\",                     # Optional whitespace at end\n",
    "    flags=re.MULTILINE | re.DOTALL       # Multi-line matching with . matching newlines\n",
    ")\n",
    "\n",
    "match_numbers = re.compile(\n",
    "    rf\"{solution_start}.*?([\\d\\.]{{1,}})\", # Extract numbers from solution section\n",
    "    flags=re.MULTILINE | re.DOTALL        # Flexible pattern matching\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward Function 1: Exact Format Compliance\n",
    "def match_format_exactly(completions, **kwargs):\n",
    "    \"\"\"\n",
    "    High reward (3.0) for perfect format adherence\n",
    "    Ensures model learns the complete structured output pattern\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for completion in completions:\n",
    "        response = completion[0][\"content\"]\n",
    "        # Check if response matches complete format pattern\n",
    "        score = 3.0 if match_format.search(response) is not None else 0.0\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward Function 2: Partial Format Credit\n",
    "def match_format_approximately(completions, **kwargs):\n",
    "    \"\"\"\n",
    "    Graduated scoring for format elements\n",
    "    Encourages learning individual components even if not perfect\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for completion in completions:\n",
    "        response = completion[0][\"content\"]\n",
    "        score = 0\n",
    "        \n",
    "        # Award +0.5 for correct token count, -0.5 for wrong count\n",
    "        score += 0.5 if response.count(reasoning_start) == 1 else -0.5\n",
    "        score += 0.5 if response.count(reasoning_end) == 1 else -0.5\n",
    "        score += 0.5 if response.count(solution_start) == 1 else -0.5\n",
    "        score += 0.5 if response.count(solution_end) == 1 else -0.5\n",
    "        \n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward Function 3: Mathematical Accuracy\n",
    "def check_answer_correctness(prompts, completions, answer, **kwargs):\n",
    "    \"\"\"\n",
    "    Graduated scoring for mathematical accuracy:\n",
    "    - 3.0: Exact match\n",
    "    - 1.5: Within 10% (close answer)\n",
    "    - 0.5: Within 20% (reasonable attempt)\n",
    "    - -0.5: Wrong answer (penalty for incorrect math)\n",
    "    \"\"\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    \n",
    "    # Extract answers using format pattern\n",
    "    extracted_responses = [\n",
    "        guess.group(1) if (guess := match_format.search(r)) is not None else None\n",
    "        for r in responses\n",
    "    ]\n",
    "    \n",
    "    scores = []\n",
    "    for guess, true_answer in zip(extracted_responses, answer):\n",
    "        if guess is None:  # No extractable answer\n",
    "            scores.append(0)\n",
    "            continue\n",
    "            \n",
    "        # Exact string match gets full points\n",
    "        if guess.strip() == true_answer.strip():\n",
    "            scores.append(3.0)\n",
    "        else:\n",
    "            # Try numerical comparison for partial credit\n",
    "            try:\n",
    "                ratio = float(guess) / float(true_answer)\n",
    "                if 0.9 <= ratio <= 1.1:      # Within 10%\n",
    "                    scores.append(1.5)\n",
    "                elif 0.8 <= ratio <= 1.2:    # Within 20%\n",
    "                    scores.append(0.5)\n",
    "                else:                         # Wrong answer\n",
    "                    scores.append(-0.5)\n",
    "            except (ValueError, ZeroDivisionError):\n",
    "                scores.append(-0.5)           # Invalid numerical format\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward Function 4: Number Extraction Ability  \n",
    "def check_numbers_extraction(prompts, completions, answer, **kwargs):\n",
    "    \"\"\"\n",
    "    Tests the model's ability to extract numerical values from solution sections\n",
    "    Complementary to exact format matching - focuses on parsing capability\n",
    "    \"\"\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    \n",
    "    # Extract numbers from solution sections using number pattern\n",
    "    extracted_responses = [\n",
    "        guess.group(1) if (guess := match_numbers.search(r)) is not None else None\n",
    "        for r in responses\n",
    "    ]\n",
    "    \n",
    "    scores = []\n",
    "    for guess, true_answer in zip(extracted_responses, answer):\n",
    "        if guess is None:  # No extractable number\n",
    "            scores.append(0)\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Simple numerical equality check\n",
    "            true_val = float(true_answer.strip())\n",
    "            guess_val = float(guess.strip())\n",
    "            # Binary scoring: correct (1.5) or incorrect (0)\n",
    "            scores.append(1.5 if guess_val == true_val else 0.0)\n",
    "        except (ValueError, TypeError):\n",
    "            scores.append(0)  # Invalid number format\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRPO Training Setup\n",
    "\n",
    "Configure training parameters optimized for mathematical reasoning with memory constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/config \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/info?serialize=False \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Trackio project initialized: GRPO-Mathematical-Reasoning\n",
      "* Trackio metrics logged to: /home/behrooz/.cache/huggingface/trackio\n",
      "* View dashboard by running in your terminal:\n",
      "\u001b[1m\u001b[93mtrackio show --project \"GRPO-Mathematical-Reasoning\"\u001b[0m\n",
      "* or by running in Python: trackio.show(project=\"GRPO-Mathematical-Reasoning\")\n",
      "🎯 GRPO Configuration Summary:\n",
      "   Learning rate: 5e-06\n",
      "   Effective batch size: 16\n",
      "   Training steps: 100\n",
      "   Generations per step: 8\n",
      "✅ Trackio experiment tracking initialized\n",
      "📊 Run name: qwen2.5-3b-gsm8k-grpo-20250823-144658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/heartbeat/d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/fastapi/applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/applications.py\", line 112, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n",
      "    raise exc\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/gradio/route_utils.py\", line 884, in __call__\n",
      "    await self.simple_response(scope, receive, send, request_headers=headers)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/gradio/route_utils.py\", line 900, in simple_response\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/routing.py\", line 714, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/routing.py\", line 734, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/routing.py\", line 288, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/routing.py\", line 76, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/routing.py\", line 73, in app\n",
      "    response = await f(request)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/fastapi/routing.py\", line 301, in app\n",
      "    raw_response = await run_endpoint_function(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n",
      "    return await dependant.call(**values)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/gradio/routes.py\", line 1320, in queue_join\n",
      "    return await queue_join_helper(body, request, username)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/gradio/routes.py\", line 1338, in queue_join_helper\n",
      "    success, event_id = await blocks._queue.push(\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/gradio/queueing.py\", line 225, in push\n",
      "    fn = session_state.blocks_config.fns[body.fn_index]\n",
      "         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "KeyError: 32\n",
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/fastapi/applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/applications.py\", line 112, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n",
      "    raise exc\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/gradio/route_utils.py\", line 884, in __call__\n",
      "    await self.simple_response(scope, receive, send, request_headers=headers)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/gradio/route_utils.py\", line 900, in simple_response\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/routing.py\", line 714, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/routing.py\", line 734, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/routing.py\", line 288, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/routing.py\", line 76, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/routing.py\", line 73, in app\n",
      "    response = await f(request)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/fastapi/routing.py\", line 301, in app\n",
      "    raw_response = await run_endpoint_function(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n",
      "    return await dependant.call(**values)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/gradio/routes.py\", line 1320, in queue_join\n",
      "    return await queue_join_helper(body, request, username)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/gradio/routes.py\", line 1338, in queue_join_helper\n",
      "    success, event_id = await blocks._queue.push(\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/gradio/queueing.py\", line 225, in push\n",
      "    fn = session_state.blocks_config.fns[body.fn_index]\n",
      "         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "KeyError: 32\n",
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 409, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/fastapi/applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/applications.py\", line 112, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n",
      "    raise exc\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/gradio/route_utils.py\", line 884, in __call__\n",
      "    await self.simple_response(scope, receive, send, request_headers=headers)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/gradio/route_utils.py\", line 900, in simple_response\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/routing.py\", line 714, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/routing.py\", line 734, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/routing.py\", line 288, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/routing.py\", line 76, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/starlette/routing.py\", line 73, in app\n",
      "    response = await f(request)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/fastapi/routing.py\", line 301, in app\n",
      "    raw_response = await run_endpoint_function(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/fastapi/routing.py\", line 212, in run_endpoint_function\n",
      "    return await dependant.call(**values)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/gradio/routes.py\", line 1320, in queue_join\n",
      "    return await queue_join_helper(body, request, username)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/gradio/routes.py\", line 1338, in queue_join_helper\n",
      "    success, event_id = await blocks._queue.push(\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/behrooz/.conda/envs/behrooz/lib/python3.11/site-packages/gradio/queueing.py\", line 225, in push\n",
      "    fn = session_state.blocks_config.fns[body.fn_index]\n",
      "         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "KeyError: 32\n"
     ]
    }
   ],
   "source": [
    "# Configure GRPO training parameters for mathematical reasoning\n",
    "training_args = GRPOConfig(\n",
    "    # Learning parameters optimized for reasoning tasks\n",
    "    learning_rate=5e-6,              # Conservative LR to prevent destabilizing reasoning\n",
    "    \n",
    "    # Memory-efficient batch configuration\n",
    "    per_device_train_batch_size=2,   # Small batch for GPU memory constraints\n",
    "    gradient_accumulation_steps=8,   # Effective batch size = 2 * 8 = 16\n",
    "    \n",
    "    # Sequence length limits for mathematical problems\n",
    "    max_prompt_length=1024,          # Sufficient for complex word problems\n",
    "    max_completion_length=1024,      # Room for detailed step-by-step reasoning\n",
    "    \n",
    "    # Training duration and monitoring\n",
    "    max_steps=100,                    # Short demo run (increase to 500+ for production)\n",
    "    logging_steps=1,                 # Log metrics every step for close monitoring\n",
    "    \n",
    "    # Stability and output configuration\n",
    "    output_dir=\"./trl_grpo_outputs\",\n",
    "    max_grad_norm=0.1,               # Aggressive gradient clipping for stable training\n",
    "    report_to=\"none\",                # Disable wandb/tensorboard (using trackio instead)\n",
    ")\n",
    "\n",
    "# Create unique run name with timestamp to ensure fresh tracking\n",
    "import datetime\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "run_name = f\"qwen2.5-3b-gsm8k-grpo-{timestamp}\"\n",
    "\n",
    "# Initialize trackio experiment tracking with unique run name\n",
    "trackio.init(\n",
    "    project=\"GRPO-Mathematical-Reasoning\",  # Project name for organization\n",
    "    name=run_name,                         # Unique run identifier with timestamp\n",
    "    config={\n",
    "        # Model and dataset configuration\n",
    "        \"model_name\": \"Qwen/Qwen2.5-3B-Instruct\",\n",
    "        \"dataset\": \"GSM8K\", \n",
    "        \"technique\": \"GRPO + LoRA + 4-bit\",\n",
    "        \n",
    "        # Training hyperparameters\n",
    "        \"learning_rate\": training_args.learning_rate,\n",
    "        \"batch_size\": training_args.per_device_train_batch_size,\n",
    "        \"gradient_accumulation_steps\": training_args.gradient_accumulation_steps,\n",
    "        \"effective_batch_size\": training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps,\n",
    "        \"max_steps\": training_args.max_steps,\n",
    "        \n",
    "        # LoRA configuration\n",
    "        \"lora_r\": 16,\n",
    "        \"lora_alpha\": 32,\n",
    "        \n",
    "        # GRPO-specific settings\n",
    "        \"num_generations\": training_args.num_generations,  # Default: 8 generations per step\n",
    "        \"max_prompt_length\": training_args.max_prompt_length,\n",
    "        \"max_completion_length\": training_args.max_completion_length,\n",
    "        \n",
    "        # Reward system\n",
    "        \"num_reward_functions\": 4,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"🎯 GRPO Configuration Summary:\")\n",
    "print(f\"   Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"   Effective batch size: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\n",
    "print(f\"   Training steps: {training_args.max_steps}\")\n",
    "print(f\"   Generations per step: {training_args.num_generations}\")\n",
    "print(f\"✅ Trackio experiment tracking initialized\")\n",
    "print(f\"📊 Run name: {run_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer Initialization with Trackio Integration\n",
    "\n",
    "Set up the GRPO trainer with our multi-reward system and experiment tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.trainer_callback import TrainerCallback\n",
    "\n",
    "class TrackioCallback(TrainerCallback):\n",
    "    \"\"\"Custom callback to log training metrics to trackio dashboard\"\"\"\n",
    "    \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        \"\"\"Capture and forward all training metrics to trackio\"\"\"\n",
    "        if logs is None:\n",
    "            return\n",
    "            \n",
    "        # Log all available metrics with current training step\n",
    "        trackio.log(logs, step=state.global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GRPO Trainer initialized successfully!\n",
      "📊 Training dataset: 7,473 examples\n",
      "🎯 Reward functions: 4 active\n",
      "📈 Trackio integration: Enabled\n",
      "🔄 Ready for training with 8 generations per step\n"
     ]
    }
   ],
   "source": [
    "# Initialize GRPO trainer with multi-reward system\n",
    "trackio_callback = TrackioCallback()  # Create trackio logging callback\n",
    "\n",
    "trainer = GRPOTrainer(\n",
    "    model=model,                      # LoRA-adapted quantized model\n",
    "    reward_funcs=[                    # Four complementary reward functions\n",
    "        match_format_exactly,         # Perfect structure compliance\n",
    "        match_format_approximately,   # Partial format credit\n",
    "        check_answer_correctness,     # Mathematical accuracy\n",
    "        check_numbers_extraction,     # Number parsing ability\n",
    "    ],\n",
    "    args=training_args,               # Training configuration\n",
    "    train_dataset=dataset,            # Processed GSM8K dataset\n",
    "    callbacks=[trackio_callback],     # Experiment tracking integration\n",
    ")\n",
    "\n",
    "print(\"✅ GRPO Trainer initialized successfully!\")\n",
    "print(f\"📊 Training dataset: {len(dataset):,} examples\")\n",
    "print(f\"🎯 Reward functions: {len(trainer.reward_funcs)} active\")\n",
    "print(f\"📈 Trackio integration: Enabled\")\n",
    "print(f\"🔄 Ready for training with {training_args.num_generations} generations per step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin GRPO Training\n",
    "\n",
    "Start the training process with real-time reward monitoring. Watch for gradual improvement in both format compliance and mathematical accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting GRPO training...\n",
      "📊 Monitor metrics: reward scores, KL divergence, policy gradients\n",
      "🔍 Trackio will log: losses, rewards, learning rate, gradients\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 2:09:34, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.057400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.028600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.052200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.024700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.029100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>-0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.044500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>-0.016900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.019700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.008800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>-0.011500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.062800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.034000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>-0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.029000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.071600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>-0.021600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.040600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>-0.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.010400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.057700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.072800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.039300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>-0.017400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>-0.015800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.021800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>-0.003900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>-0.012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.078400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.006100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>-0.017600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.011400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.040700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.087900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.039700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.013600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>-0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>-0.059300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.065500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.040900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.009300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>-0.006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>-0.038200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.076200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.013900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>-0.023400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>-0.047900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>-0.033100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>-0.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.011600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.069600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.003500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>-0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>-0.019100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>-0.058800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.029700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.084700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>-0.005200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>-0.033000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.027900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>-0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>-0.017900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.110500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>-0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>-0.051100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.017700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.051800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.024400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>-0.014700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>-0.044400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>-0.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.062100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.063300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>-0.006400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.022300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.016100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>-0.006700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>-0.049500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>-0.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>-0.039100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.006100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.092600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>-0.010400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.005600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.057300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>-0.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.029400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>-0.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.053700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.064100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>-0.002100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>-0.007800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>-0.011300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:7860/gradio_api/queue/join \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/queue/data?session_hash=d1188e83-f58f-48ba-9da1-10a6d6a753c9 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training completed successfully!\n",
      "💾 Model saved to: ./trl_grpo_outputs\n"
     ]
    }
   ],
   "source": [
    "# Execute GRPO training with multi-reward optimization\n",
    "print(\"🚀 Starting GRPO training...\")\n",
    "print(\"📊 Monitor metrics: reward scores, KL divergence, policy gradients\")\n",
    "print(\"🔍 Trackio will log: losses, rewards, learning rate, gradients\")\n",
    "\n",
    "# Run the training process\n",
    "trainer.train()\n",
    "\n",
    "# Complete the trackio experiment\n",
    "trackio.finish()\n",
    "\n",
    "print(\"✅ Training completed successfully!\")\n",
    "print(f\"💾 Model saved to: {training_args.output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Dashboard\n",
    "\n",
    "Launch the interactive trackio dashboard to analyze training progress, reward evolution, and model performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Trackio UI launched at: http://127.0.0.1:7860/?project=GRPO-Mathematical-Reasoning\n"
     ]
    }
   ],
   "source": [
    "# Launch interactive trackio dashboard for experiment analysis\n",
    "# View training curves, reward progression, loss evolution, and hyperparameter effects\n",
    "trackio.show(project=\"GRPO-Mathematical-Reasoning\")\n",
    "\n",
    "# Alternative: Launch from command line with: trackio show --project \"GRPO-Mathematical-Reasoning\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation and Testing\n",
    "\n",
    "Test the trained model's mathematical reasoning capability with structured output validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model testing function with optimized generation parameters\n",
    "def test_model(question, max_length=512):\n",
    "    \"\"\"\n",
    "    Test the trained model on mathematical questions\n",
    "    \n",
    "    Args:\n",
    "        question (str): Mathematical problem to solve\n",
    "        max_length (int): Maximum tokens to generate\n",
    "        \n",
    "    Returns:\n",
    "        str: Model's structured response with reasoning and solution\n",
    "    \"\"\"\n",
    "    # Format input using conversation template\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "    ]\n",
    "    \n",
    "    # Apply chat template and tokenize\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,      # Add assistant prompt\n",
    "        tokenize=False,                  # Return string, not tokens\n",
    "    )\n",
    "    \n",
    "    # Tokenize and move to appropriate device\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    print(f\"🤔 Processing: {question}\")\n",
    "    \n",
    "    # Generate response with reasoning-optimized parameters\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_length,\n",
    "            temperature=0.7,                    # Balance creativity and consistency\n",
    "            do_sample=True,                     # Enable sampling for varied reasoning paths\n",
    "            top_p=0.9,                         # Nucleus sampling for quality\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            repetition_penalty=1.1,            # Reduce repetitive reasoning steps\n",
    "            length_penalty=1.0,                # Neutral preference for response length\n",
    "            early_stopping=True,               # Stop at natural completion\n",
    "        )\n",
    "    \n",
    "    # Decode and extract only the generated portion\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    generated_text = response[len(text):].strip()\n",
    "    \n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Test the trained model with a GSM8K problem and validate structured output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤔 Processing: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
      "Question: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
      "Model Response:\n",
      "tart_working_out>\n",
      "First, determine how many clips Natalia sold in May by finding half the number she sold in April. Then, add the sales from both months to find the total.\n",
      "\n",
      "- Sales in April: 48 clips\n",
      "- Sales in May: Half as much as in April, which is \\( \\frac{1}{2} \\times 48 \\)\n",
      "\n",
      "Next, compute the value for sales in May:\n",
      "\\[ \\text{Sales in May} = \\frac{1}{2} \\times 48 = 24 \\]\n",
      "\n",
      "Now calculate the total sales over April and May:\n",
      "\\[ \\text{Total sales} = \\text{Sales in April} + \\text{Sales in May} = 48 + 24 = 72 \\]\n",
      "\n",
      "So, the total number of clips sold in April and May combined is 72.\n",
      "\n",
      "<end_working_out>\n",
      "\n",
      "Therefore, according to my calculations:\n",
      "\n",
      "<SOLUTION>72</SOLUTION>\n",
      "\n",
      "</SOLUTION>\n",
      "\n",
      "Format Check:\n",
      "Reasoning section: False\n",
      "Solution section: True\n",
      "Extracted: 72\n",
      "Expected: 72\n",
      "Correct: True\n"
     ]
    }
   ],
   "source": [
    "# Test model on GSM8K problem\n",
    "gsm8k_question = \"Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\"\n",
    "expected_answer = \"72\"\n",
    "\n",
    "# Generate response\n",
    "gsm8k_response = test_model(gsm8k_question, max_length=768)\n",
    "\n",
    "print(f\"Question: {gsm8k_question}\")\n",
    "print(f\"Model Response:\\n{gsm8k_response}\")\n",
    "\n",
    "# Validate format compliance\n",
    "has_reasoning = reasoning_start in gsm8k_response and reasoning_end in gsm8k_response\n",
    "has_solution = solution_start in gsm8k_response and solution_end in gsm8k_response\n",
    "\n",
    "print(f\"\\nFormat Check:\")\n",
    "print(f\"Reasoning section: {has_reasoning}\")\n",
    "print(f\"Solution section: {has_solution}\")\n",
    "\n",
    "# Check answer accuracy if solution section exists\n",
    "if has_solution:\n",
    "    try:\n",
    "        solution_text = gsm8k_response.split(solution_start)[1].split(solution_end)[0].strip()\n",
    "        extracted_number = ''.join(filter(str.isdigit, solution_text))\n",
    "        expected_number = ''.join(filter(str.isdigit, expected_answer))\n",
    "        is_correct = extracted_number == expected_number\n",
    "        \n",
    "        print(f\"Extracted: {solution_text}\")\n",
    "        print(f\"Expected: {expected_answer}\")\n",
    "        print(f\"Correct: {is_correct}\")\n",
    "    except:\n",
    "        print(\"Could not extract solution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up Resources\n",
    "\n",
    "Free GPU memory and clear cached tensors for optimal resource management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def remove_trackio_project(project_name):\n",
    "    \"\"\"Remove a trackio project by deleting its database file\"\"\"\n",
    "    cache_dir = Path.home() / \".cache\" / \"huggingface\" / \"trackio\"\n",
    "    db_file = cache_dir / f\"{project_name}.db\"\n",
    "    \n",
    "    if db_file.exists():\n",
    "        db_file.unlink()\n",
    "        print(f\"Removed trackio project: {project_name}\")\n",
    "    else:\n",
    "        print(f\"Project not found: {project_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up trackio experiment database to free storage space\n",
    "# WARNING: This permanently deletes all experiment logs and metrics\n",
    "remove_trackio_project(\"GRPO-Mathematical-Reasoning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free GPU memory and clear Python garbage collection\n",
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()  # Clear PyTorch CUDA memory cache\n",
    "gc.collect()              # Run Python garbage collector\n",
    "\n",
    "print(\"✅ GPU memory cache cleared\")\n",
    "print(\"✅ Python garbage collection completed\")\n",
    "print(\"🧹 Resources freed for other processes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "### Papers and Research\n",
    "- **GRPO Algorithm**: [Group Relative Policy Optimization](https://arxiv.org/abs/2402.03300) - The original GRPO paper introducing group-based relative policy optimization\n",
    "- **GSM8K Dataset**: [Training Verifiers to Solve Math Word Problems](https://arxiv.org/abs/2110.14168) - Cobbe et al., OpenAI\n",
    "- **LoRA**: [Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685) - Hu et al., Microsoft\n",
    "- **QLoRA**: [Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314) - Dettmers et al., 4-bit quantization for efficient training\n",
    "\n",
    "### Libraries and Frameworks\n",
    "- **TRL (Transformers Reinforcement Learning)**: [HuggingFace TRL](https://github.com/huggingface/trl) - Official library for RLHF and advanced training techniques\n",
    "- **Transformers**: [HuggingFace Transformers](https://github.com/huggingface/transformers) - State-of-the-art NLP library\n",
    "- **PEFT**: [Parameter-Efficient Fine-Tuning](https://github.com/huggingface/peft) - Efficient adaptation methods\n",
    "- **BitsAndBytes**: [8-bit & 4-bit Quantization](https://github.com/TimDettmers/bitsandbytes) - Memory-efficient training\n",
    "\n",
    "### Models Used\n",
    "- **Qwen2.5-3B-Instruct**: [Qwen Model Series](https://github.com/QwenLM/Qwen2.5) - Alibaba's instruction-tuned language model\n",
    "- **Alternative Models**: Gemma-2B, DialoGPT, GPT-2 (configurable in the notebook)\n",
    "\n",
    "### Datasets\n",
    "- **GSM8K**: [OpenAI GSM8K](https://huggingface.co/datasets/openai/gsm8k) - Grade School Math 8K problems dataset\n",
    "- **Format**: Mathematical word problems requiring multi-step reasoning and numerical answers\n",
    "\n",
    "### Key Concepts\n",
    "- **Reinforcement Learning from Human Feedback (RLHF)**: Training language models using reward signals\n",
    "- **Group Relative Policy Optimization**: Advanced RL technique comparing responses in groups rather than absolute scoring\n",
    "- **Structured Generation**: Teaching models to follow specific output formats with reasoning sections\n",
    "- **Multi-Reward Training**: Using multiple reward functions for comprehensive evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "behrooz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
